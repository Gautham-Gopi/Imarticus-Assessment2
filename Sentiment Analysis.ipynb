{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78185067",
   "metadata": {},
   "source": [
    "### Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cb5910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gautham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gautham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import math\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b113710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775ab118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0930ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfea108",
   "metadata": {},
   "source": [
    "### Total Number of Positive and Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac731494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count :  2236\n",
      "Negative count :  8493\n",
      "Total positive and negative count :  10729\n"
     ]
    }
   ],
   "source": [
    "p_count = 0\n",
    "n_count = 0\n",
    "for i in df[\"sentiment\"]:\n",
    "    if i == \"Positive\":\n",
    "        p_count += 1\n",
    "    elif i == \"Negative\":\n",
    "        n_count += 1\n",
    "print(\"Positive count : \", p_count)\n",
    "print(\"Negative count : \", n_count)\n",
    "print(\"Total positive and negative count : \", p_count + n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2caded3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"] != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7c6a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf6a92",
   "metadata": {},
   "source": [
    "### Sequential LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c758b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5  Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6  Negative  RT @warriorwoman91: I liked her and was happy ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[[\"sentiment\", \"text\"]]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4c299",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae112d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'RT' from the text\n",
    "def remove_tags(string):\n",
    "    removelist = \"\"\n",
    "    result = re.sub('RT','',string) # Remove RT from text         \n",
    "    result = result.lower()\n",
    "    return result\n",
    "df_new['text'] = df_new['text'].apply(lambda cw : remove_tags(cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a92fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_new['text'] = df_new['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9cb2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12739</th>\n",
       "      <td>Positive</td>\n",
       "      <td>bwahaha!! love #tweet! #gopdebate #gopdebates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>Negative</td>\n",
       "      <td>#gopdebate 1st episode #foxnews new reality sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@fmjamerican: megyn kelly chris wallace brett ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>Negative</td>\n",
       "      <td>guess i'm grateful rand paul allowing use word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>Negative</td>\n",
       "      <td>#gopdebates #gop2016 plan building military cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@kimguilfoyle: two great debates! favorites? l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@monaeltahawy: candidate received word god?! p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@annebayefsky: .@chrischristie faced â€œthe #oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl: wondering fox debate -- get rid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10846</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@rwsurfergirl: fox news obviously trying influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@kesgardner: brutal question assclown megan ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@vishaldisawar: dear @foxnews, stop using word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@cocainesowhlte: cocaine white watching #gopde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@rwsurfergirl: thanks fox news, raising @reald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@melslien: winner tonight's #gopdebate was: me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "12739  Positive  bwahaha!! love #tweet! #gopdebate #gopdebates ...\n",
       "4561   Negative  #gopdebate 1st episode #foxnews new reality sh...\n",
       "3461   Negative  @fmjamerican: megyn kelly chris wallace brett ...\n",
       "4224   Negative  guess i'm grateful rand paul allowing use word...\n",
       "9046   Negative  #gopdebates #gop2016 plan building military cu...\n",
       "8053   Positive  @kimguilfoyle: two great debates! favorites? l...\n",
       "10515  Negative  @monaeltahawy: candidate received word god?! p...\n",
       "2433   Negative  @annebayefsky: .@chrischristie faced â€œthe #oba...\n",
       "13809  Negative  @rwsurfergirl: wondering fox debate -- get rid...\n",
       "10846  Negative  @rwsurfergirl: fox news obviously trying influ...\n",
       "268    Positive  @kesgardner: brutal question assclown megan ke...\n",
       "2980   Negative  @vishaldisawar: dear @foxnews, stop using word...\n",
       "1438   Negative  @cocainesowhlte: cocaine white watching #gopde...\n",
       "12740  Positive  @rwsurfergirl: thanks fox news, raising @reald...\n",
       "7833   Positive  @melslien: winner tonight's #gopdebate was: me..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing text\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "df_new['text'] = df_new.text.apply(lemmatize_text)\n",
    "df_new.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b375ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Labels\n",
    "reviews = df_new[\"text\"].values\n",
    "labels = df_new[\"sentiment\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de07e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14fc9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Sentences\n",
    "vocab_size = 3000 \n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 \n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d2f64",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad091301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 100)          300000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,601\n",
      "Trainable params: 387,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b90ffb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "227/227 [==============================] - 23s 91ms/step - loss: 0.4231 - accuracy: 0.8231 - val_loss: 0.3392 - val_accuracy: 0.8634\n",
      "Epoch 2/7\n",
      "227/227 [==============================] - 18s 78ms/step - loss: 0.2783 - accuracy: 0.8830 - val_loss: 0.3298 - val_accuracy: 0.8671\n",
      "Epoch 3/7\n",
      "227/227 [==============================] - 17s 75ms/step - loss: 0.2287 - accuracy: 0.9037 - val_loss: 0.3471 - val_accuracy: 0.8484\n",
      "Epoch 4/7\n",
      "227/227 [==============================] - 17s 76ms/step - loss: 0.1953 - accuracy: 0.9166 - val_loss: 0.3835 - val_accuracy: 0.8596\n",
      "Epoch 5/7\n",
      "227/227 [==============================] - 18s 79ms/step - loss: 0.1676 - accuracy: 0.9336 - val_loss: 0.4133 - val_accuracy: 0.8509\n",
      "Epoch 6/7\n",
      "227/227 [==============================] - 18s 79ms/step - loss: 0.1411 - accuracy: 0.9453 - val_loss: 0.5323 - val_accuracy: 0.8584\n",
      "Epoch 7/7\n",
      "227/227 [==============================] - 18s 81ms/step - loss: 0.1239 - accuracy: 0.9511 - val_loss: 0.4772 - val_accuracy: 0.8335\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 7\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs = num_epochs, verbose = 1, \n",
    "                    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61982454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction : 0.8147595974655236\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction :\", accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb312e8a",
   "metadata": {},
   "source": [
    "### Checking sentiments for the given sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e71af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a great leader.\n",
      "Predicted sentiment :  Positive\n",
      "He is a terrible leader.\n",
      "Predicted sentiment :  Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"He is a great leader.\", \n",
    "            \"He is a terrible leader.\"]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "prediction = model.predict(padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "        \n",
    "for i in range(len(sentence)):\n",
    "    print(sentence[i])\n",
    "    if pred_labels[i] == 1:\n",
    "        s = 'Positive'\n",
    "    else:\n",
    "        s = 'Negative'\n",
    "    print(\"Predicted sentiment : \",s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2a24a",
   "metadata": {},
   "source": [
    "### The model predicted the following sentiments for the given sentences:\n",
    "### He is a great leader : Positive\n",
    "### He is a terrible leader : Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028fad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
